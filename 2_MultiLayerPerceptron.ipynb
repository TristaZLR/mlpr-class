{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a classification task that has two-dimensional feature vectors $(x_1, x_2)$ as input.\n",
    "We make a dataset that looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Np1 = 15\n",
    "Np2 = 15\n",
    "Nn = 30\n",
    "N = Np1 + Np2 + Nn\n",
    "xp1s = torch.randn(Np1, 2) + torch.Tensor([5.0, -5.0])\n",
    "xp2s = torch.randn(Np2, 2) + torch.Tensor([-5.0, 5.0])\n",
    "xns = torch.randn(Nn, 2) @ torch.Tensor([[2.0, 1.0], [-1.0, -2.0]])\n",
    "xs = torch.cat((xp1s, xp2s, xns))\n",
    "plt.scatter(xp1s[:, 0], xp1s[:, 1], color='red')\n",
    "plt.scatter(xp2s[:, 0], xp2s[:, 1], color='red')\n",
    "plt.scatter(xns[:, 0], xns[:, 1], color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_true = torch.cat((torch.ones(Np1 + Np2), torch.zeros(Nn)))\n",
    "ys_true = ys_true.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for experimental purpose, let's see the logistic regression fails to classify this dataset because of its linearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(2, 1)\n",
    "bce_with_sigmoid = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(linear.parameters(), lr = 0.1)\n",
    "for epoch in range(300):\n",
    "    zs = linear(xs)\n",
    "    loss = bce_with_sigmoid(zs, ys_true)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ys_pred = torch.sigmoid(linear(xs))\n",
    "xs_classified_pos = xs[ys_pred[:,0]>0.5]\n",
    "xs_classified_neg = xs[ys_pred[:,0]<=0.5]\n",
    "plt.scatter(xs_classified_pos[:, 0], xs_classified_pos[:, 1], color='red')\n",
    "plt.scatter(xs_classified_neg[:, 0], xs_classified_neg[:, 1], color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we add a hidden layer to increase the expressive power of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "linear1 = nn.Linear(2, 2)\n",
    "linear2 = nn.Linear(2, 1)\n",
    "bce_with_sigmoid = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(chain(linear1.parameters(), linear2.parameters()), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(3000):\n",
    "    z1s = linear1(xs)\n",
    "    z1s = torch.sigmoid(z1s)\n",
    "    z2s = linear2(z1s)\n",
    "    loss = bce_with_sigmoid(z2s, ys_true)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z1s = linear1(xs)\n",
    "z1s = torch.sigmoid(z1s)\n",
    "z2s = linear2(z1s)\n",
    "ys_pred = torch.sigmoid(z2s)\n",
    "xs_classified_pos = xs[ys_pred[:,0]>0.5]\n",
    "xs_classified_neg = xs[ys_pred[:,0]<=0.5]\n",
    "plt.scatter(xs_classified_pos[:, 0], xs_classified_pos[:, 1], color='red')\n",
    "plt.scatter(xs_classified_neg[:, 0], xs_classified_neg[:, 1], color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we get a wrong classification.\n",
    "In that case, retry the initialization of the model and run the training again.\n",
    "This is an issue of falling local minimum, which generally exists in gradient-based optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, I intentionally describe the model in a naive way, but a model in PyTorch is usually defined by defining a class extending `nn.Module` as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, xs):\n",
    "        z1s = self.linear1(xs)\n",
    "        z1s = torch.sigmoid(z1s)\n",
    "        z2s = self.linear2(z1s)\n",
    "        return z2s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model class has to implement at least two methods.\n",
    "\n",
    "`__init__` is a method that is called once at first, and usually supposed to create instances involving model parameters.\n",
    "The model parameters instantiated here is captured by the superclass `nn.Module` so that you can easily obtain the list of parameters in the model.\n",
    "\n",
    "`forward` is a method that is typically supposed to transform an input `xs`.\n",
    "This is automatically called when we call the instance of the model, as we see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = MLP(2, 2, 1)\n",
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = model(xs) # forward() method is called through __call__() method in nn.Module\n",
    "print(zs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training and testing code can be described in a simplar way, as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(2, 2, 1)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
    "for epoch in range(3000):\n",
    "    zs = model(xs)\n",
    "    loss = bce_with_sigmoid(zs, ys_true)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ys_pred = torch.sigmoid(model(xs))\n",
    "xs_classified_pos = xs[ys_pred[:,0]>0.5]\n",
    "xs_classified_neg = xs[ys_pred[:,0]<=0.5]\n",
    "plt.scatter(xs_classified_pos[:, 0], xs_classified_pos[:, 1], color='red')\n",
    "plt.scatter(xs_classified_neg[:, 0], xs_classified_neg[:, 1], color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
